{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python 3.8.18\n",
    "\n",
    "# 🧠 NL2SQL 中文模型訓練與查詢範例\n",
    "# 本 Notebook 示範如何：\n",
    "# - 使用 HuggingFace Transformers 微調 T5 模型進行中文轉 SQL 訓練\n",
    "# - 以中文自然語言問題生成 SQL 語句\n",
    "# - 查詢 SQLite 資料庫並顯示結果表格\n",
    "\n",
    "# !pip install transformers sentencepiece datasets accelerate pandas --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立測試資料庫 + 執行 SQL 查詢\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# 建立測試 customers 表格\n",
    "conn = sqlite3.connect(\"sample_nl2sql.db\")\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"DROP TABLE IF EXISTS customers\")\n",
    "cursor.execute(\"\"\"CREATE TABLE customers (\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    name TEXT,\n",
    "    city TEXT\n",
    ")\"\"\")\n",
    "\n",
    "cursor.executemany(\n",
    "    \"INSERT INTO customers (name, city) VALUES (?, ?)\",\n",
    "    [\n",
    "        (\"小明\", \"台北\"),\n",
    "        (\"小美\", \"台中\"),\n",
    "        (\"大雄\", \"台北\"),\n",
    "        (\"靜香\", \"台南\"),\n",
    "        (\"胖虎\", \"高雄\"),\n",
    "        (\"阿信\", \"新北\"),\n",
    "        (\"怡君\", \"桃園\"),\n",
    "        (\"柏翰\", \"台中\"),\n",
    "        (\"冠宇\", \"新竹\"),\n",
    "        (\"雅婷\", \"台南\"),\n",
    "        (\"詠晴\", \"高雄\"),\n",
    "        (\"建志\", \"台北\"),\n",
    "        (\"欣怡\", \"台中\"),\n",
    "        (\"威廷\", \"嘉義\"),\n",
    "        (\"志偉\", \"花蓮\"),\n",
    "        (\"家豪\", \"台南\"),\n",
    "        (\"佩珊\", \"基隆\"),\n",
    "        (\"明秀\", \"新北\"),\n",
    "        (\"柏宏\", \"桃園\"),\n",
    "        (\"志芳\", \"宜蘭\"),\n",
    "        (\"佳怡\", \"屏東\"),\n",
    "        (\"智翔\", \"台中\"),\n",
    "        (\"婉婷\", \"新竹\"),\n",
    "        (\"詠翔\", \"高雄\"),\n",
    "        (\"俊宏\", \"台東\"),\n",
    "        (\"佳蓉\", \"苗栗\"),\n",
    "        (\"宜庭\", \"台北\"),\n",
    "        (\"冠霖\", \"南投\"),\n",
    "        (\"佳玲\", \"台中\"),\n",
    "        (\"惠雯\", \"嘉義\"),\n",
    "        (\"昱廷\", \"新北\"),\n",
    "        (\"沛瑜\", \"基隆\"),\n",
    "        (\"志明\", \"台南\"),\n",
    "        (\"冠瑋\", \"彰化\"),\n",
    "        (\"欣妤\", \"台中\"),\n",
    "        (\"志賢\", \"桃園\"),\n",
    "        (\"柏睿\", \"高雄\"),\n",
    "        (\"怡萱\", \"台北\"),\n",
    "        (\"子芸\", \"花蓮\"),\n",
    "        (\"俊賢\", \"新竹\"),\n",
    "        (\"家榮\", \"台中\"),\n",
    "        (\"宥蓉\", \"南投\"),\n",
    "        (\"品妤\", \"宜蘭\"),\n",
    "        (\"育廷\", \"屏東\"),\n",
    "        (\"湘婷\", \"新北\"),\n",
    "        (\"恩綺\", \"桃園\"),\n",
    "        (\"志華\", \"高雄\"),\n",
    "        (\"怡靜\", \"台中\"),\n",
    "        (\"哲瑋\", \"新竹\"),\n",
    "        (\"嘉容\", \"苗栗\"),\n",
    "        (\"昀潔\", \"基隆\")\n",
    "     \n",
    "     ]\n",
    ")\n",
    "conn.commit()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramData\\Anaconda3\\envs\\python38_cuda_conda\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import json, os\n",
    "from datasets import Dataset\n",
    "from transformers import T5Tokenizer, AutoTokenizer, AutoModelForSeq2SeqLM, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 定義你的資料庫 schema\n",
    "#    對每個 table，列出它的欄位名稱\n",
    "schemas = {\n",
    "    \"customers\": {\n",
    "        \"columns\": [\"name\", \"city\"]\n",
    "    }\n",
    "    # 如果有多張表，就繼續加下去：\n",
    "    # \"orders\": {\"columns\": [\"order_id\", \"customer_id\", \"amount\"]},\n",
    "}\n",
    "\n",
    "# 2. 建立訓練資料（同時帶入 schema）\n",
    "train_data = [\n",
    "    {\"question\": \"查詢所有顧客的姓名\", \"query\": \"SELECT name FROM customers;\"},\n",
    "    {\"question\": \"列出所有住在台北的顧客\", \"query\": \"SELECT * FROM customers WHERE city = '台北';\"},\n",
    "    {\"question\": \"查詢所有顧客的姓名和所在城市\", \"query\": \"SELECT name, city FROM customers;\"},\n",
    "    {\"question\": \"找出城市為高雄的顧客姓名\", \"query\": \"SELECT name FROM customers WHERE city = '高雄';\"},\n",
    "    {\"question\": \"請給我住在台中的顧客名單\", \"query\": \"SELECT * FROM customers WHERE city = '台中';\"},\n",
    "    {\"question\": \"顯示所有顧客資訊\", \"query\": \"SELECT * FROM customers;\"},\n",
    "    {\"question\": \"列出住在新北的所有顧客姓名\", \"query\": \"SELECT name FROM customers WHERE city = '新北';\"},\n",
    "    {\"question\": \"查詢在嘉義的顧客\", \"query\": \"SELECT * FROM customers WHERE city = '嘉義';\"},\n",
    "    {\"question\": \"有哪些人住在基隆？\", \"query\": \"SELECT name FROM customers WHERE city = '基隆';\"},\n",
    "    {\"question\": \"請列出所有來自桃園的顧客\", \"query\": \"SELECT * FROM customers WHERE city = '桃園';\"},\n",
    "    {\"question\": \"找出台南的顧客\", \"query\": \"SELECT * FROM customers WHERE city = '台南';\"},\n",
    "    {\"question\": \"列出台東的所有顧客\", \"query\": \"SELECT * FROM customers WHERE city = '台東';\"},\n",
    "    {\"question\": \"查詢住在宜蘭的顧客姓名\", \"query\": \"SELECT name FROM customers WHERE city = '宜蘭';\"},\n",
    "    {\"question\": \"給我住在南投的所有人名\", \"query\": \"SELECT name FROM customers WHERE city = '南投';\"},\n",
    "    {\"question\": \"住在屏東的顧客有哪些？\", \"query\": \"SELECT * FROM customers WHERE city = '屏東';\"},\n",
    "    {\"question\": \"苗栗地區有哪些顧客\", \"query\": \"SELECT * FROM customers WHERE city = '苗栗';\"},\n",
    "    {\"question\": \"查詢所有顧客的城市\", \"query\": \"SELECT city FROM customers;\"},\n",
    "    {\"question\": \"請顯示住在花蓮的所有顧客姓名\", \"query\": \"SELECT name FROM customers WHERE city = '花蓮';\"},\n",
    "    {\"question\": \"列出來自新竹的顧客\", \"query\": \"SELECT * FROM customers WHERE city = '新竹';\"},\n",
    "    {\"question\": \"哪些顧客來自彰化？\", \"query\": \"SELECT name FROM customers WHERE city = '彰化';\"},\n",
    "    {\"question\": \"找出台北的顧客有哪些\", \"query\": \"SELECT * FROM customers WHERE city = '台北';\"},\n",
    "    {\"question\": \"顯示來自各城市的顧客資訊\", \"query\": \"SELECT name, city FROM customers;\"},\n",
    "    {\"question\": \"查詢所有來自台中的顧客姓名\", \"query\": \"SELECT name FROM customers WHERE city = '台中';\"},\n",
    "    {\"question\": \"有哪些顧客是來自高雄\", \"query\": \"SELECT * FROM customers WHERE city = '高雄';\"},\n",
    "    {\"question\": \"住在基隆的有誰？\", \"query\": \"SELECT name FROM customers WHERE city = '基隆';\"},\n",
    "    {\"question\": \"請列出所有住在新北的顧客資料\", \"query\": \"SELECT * FROM customers WHERE city = '新北';\"},\n",
    "    {\"question\": \"列出所有人與他們的城市\", \"query\": \"SELECT name, city FROM customers;\"},\n",
    "    {\"question\": \"台南有多少顧客\", \"query\": \"SELECT COUNT(*) FROM customers WHERE city = '台南';\"},\n",
    "    {\"question\": \"基隆有多少顧客\", \"query\": \"SELECT COUNT(*) FROM customers WHERE city = '基隆';\"},\n",
    "    {\"question\": \"高雄有多少顧客\", \"query\": \"SELECT COUNT(*) FROM customers WHERE city = '高雄';\"},\n",
    "    {\"question\": \"新北有多少顧客\", \"query\": \"SELECT COUNT(*) FROM customers WHERE city = '新北';\"},\n",
    "    {\"question\": \"台中有多少顧客\", \"query\": \"SELECT COUNT(*) FROM customers WHERE city = '台中';\"},\n",
    "    {\"question\": \"彰化有多少顧客\", \"query\": \"SELECT COUNT(*) FROM customers WHERE city = '彰化';\"},\n",
    "    {\"question\": \"南投有多少顧客\", \"query\": \"SELECT COUNT(*) FROM customers WHERE city = '南投';\"},\n",
    "    {\"question\": \"苗栗有多少顧客\", \"query\": \"SELECT COUNT(*) FROM customers WHERE city = '苗栗';\"},\n",
    "    {\"question\": \"花蓮有多少顧客\", \"query\": \"SELECT COUNT(*) FROM customers WHERE city = '花蓮';\"},\n",
    "    {\"question\": \"嘉義有多少顧客\", \"query\": \"SELECT COUNT(*) FROM customers WHERE city = '嘉義';\"},\n",
    "    {\"question\": \"屏東有多少顧客\", \"query\": \"SELECT COUNT(*) FROM customers WHERE city = '屏東';\"},\n",
    "    {\"question\": \"宜蘭有多少顧客\", \"query\": \"SELECT COUNT(*) FROM customers WHERE city = '宜蘭';\"},\n",
    "    {\"question\": \"找出來自台東的所有人\", \"query\": \"SELECT name FROM customers WHERE city = '台東';\"},\n",
    "    {\"question\": \"查詢住在宜蘭的所有人\", \"query\": \"SELECT * FROM customers WHERE city = '宜蘭';\"},\n",
    "    {\"question\": \"列出來自南投的顧客姓名\", \"query\": \"SELECT name FROM customers WHERE city = '南投';\"},\n",
    "    {\"question\": \"顯示桃園的顧客資料\", \"query\": \"SELECT * FROM customers WHERE city = '桃園';\"},\n",
    "    {\"question\": \"列出住在屏東的顧客名單\", \"query\": \"SELECT name FROM customers WHERE city = '屏東';\"},\n",
    "    {\"question\": \"請給我所有城市為苗栗的顧客\", \"query\": \"SELECT * FROM customers WHERE city = '苗栗';\"},\n",
    "    {\"question\": \"花蓮有哪些顧客\", \"query\": \"SELECT name FROM customers WHERE city = '花蓮';\"},\n",
    "    {\"question\": \"顯示所有來自新竹的顧客資料\", \"query\": \"SELECT * FROM customers WHERE city = '新竹';\"},\n",
    "    {\"question\": \"彰化的顧客有哪些人\", \"query\": \"SELECT * FROM customers WHERE city = '彰化';\"},\n",
    "    {\"question\": \"查詢所有顧客名字\", \"query\": \"SELECT name FROM customers;\"},\n",
    "    {\"question\": \"列出台北顧客資訊\", \"query\": \"SELECT * FROM customers WHERE city = '台北';\"},\n",
    "    {\"question\": \"請顯示台中所有顧客資料\", \"query\": \"SELECT * FROM customers WHERE city = '台中';\"},\n",
    "    {\"question\": \"新北有哪些顧客姓名\", \"query\": \"SELECT name FROM customers WHERE city = '新北';\"},\n",
    "    {\"question\": \"找出所有住在嘉義的顧客\", \"query\": \"SELECT * FROM customers WHERE city = '嘉義';\"},\n",
    "    {\"question\": \"列出所有來自基隆的顧客\", \"query\": \"SELECT * FROM customers WHERE city = '基隆';\"},\n",
    "    {\"question\": \"請列出來自花蓮的所有顧客姓名\", \"query\": \"SELECT name FROM customers WHERE city = '花蓮';\"},\n",
    "    {\"question\": \"有哪些人來自台東\", \"query\": \"SELECT * FROM customers WHERE city = '台東';\"},\n",
    "    {\"question\": \"苗栗的顧客名單\", \"query\": \"SELECT name FROM customers WHERE city = '苗栗';\"},\n",
    "    {\"question\": \"住在宜蘭的人有哪些\", \"query\": \"SELECT name FROM customers WHERE city = '宜蘭';\"},\n",
    "    {\"question\": \"顯示所有在南投的顧客資料\", \"query\": \"SELECT * FROM customers WHERE city = '南投';\"},\n",
    "    {\"question\": \"有哪些顧客是來自屏東的\", \"query\": \"SELECT * FROM customers WHERE city = '屏東';\"}\n",
    "]\n",
    "with open(\"train.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(train_data, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "# 3. 載入模型與 tokenizer\n",
    "model_name = \"Langboat/mengzi-t5-base\"\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name, use_fast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 60/60 [00:00<00:00, 1819.15 examples/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 4. 構造 Dataset 並做 preprocess\n",
    "with open(\"train.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_data = json.load(f)\n",
    "data = Dataset.from_list(raw_data)\n",
    "\n",
    "def preprocess(example):\n",
    "    # 把所有 table(schema) 拼成一個字串\n",
    "    schema_strs = []\n",
    "    for table, info in schemas.items():\n",
    "        cols = \", \".join(info[\"columns\"])\n",
    "        schema_strs.append(f\"{table}({cols})\")\n",
    "    schema_text = \" | \".join(schema_strs)\n",
    "\n",
    "    # 將 question 與 schema 串在一起\n",
    "    input_text = f\"將下列中文問題轉成 SQL：{example['question']} [SEP] 資料表結構：{schema_text}\"\n",
    "    # tokenize\n",
    "    in_enc = tokenizer(\n",
    "        input_text,\n",
    "        truncation=True, padding=\"max_length\", max_length=128\n",
    "    )\n",
    "    tgt_enc = tokenizer(\n",
    "        example[\"query\"],\n",
    "        truncation=True, padding=\"max_length\", max_length=128\n",
    "    )\n",
    "    in_enc[\"labels\"] = tgt_enc[\"input_ids\"]\n",
    "    return in_enc\n",
    "\n",
    "tokenized = data.map(preprocess, remove_columns=data.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/150 [00:00<?, ?it/s]Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "  7%|▋         | 11/150 [00:05<00:35,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 9.6019, 'grad_norm': 12.290719032287598, 'learning_rate': 4.666666666666667e-05, 'epoch': 0.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 21/150 [00:11<00:51,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7681, 'grad_norm': 2.913479804992676, 'learning_rate': 4.3333333333333334e-05, 'epoch': 1.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 30/150 [00:13<00:27,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1994, 'grad_norm': 1.306185007095337, 'learning_rate': 4e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 41/150 [00:19<00:27,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0934, 'grad_norm': 1.3378885984420776, 'learning_rate': 3.6666666666666666e-05, 'epoch': 2.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 51/150 [00:24<00:37,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0585, 'grad_norm': 0.9646466374397278, 'learning_rate': 3.3333333333333335e-05, 'epoch': 3.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 60/150 [00:26<00:20,  4.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0343, 'grad_norm': 0.32992836833000183, 'learning_rate': 3e-05, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 71/150 [00:32<00:20,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0186, 'grad_norm': 0.39878204464912415, 'learning_rate': 2.6666666666666667e-05, 'epoch': 4.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 81/150 [00:37<00:26,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0158, 'grad_norm': 0.6303594708442688, 'learning_rate': 2.3333333333333336e-05, 'epoch': 5.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 90/150 [00:39<00:13,  4.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0152, 'grad_norm': 0.47316381335258484, 'learning_rate': 2e-05, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 101/150 [00:45<00:12,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0101, 'grad_norm': 0.4307566285133362, 'learning_rate': 1.6666666666666667e-05, 'epoch': 6.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 111/150 [00:51<00:15,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0083, 'grad_norm': 0.45548078417778015, 'learning_rate': 1.3333333333333333e-05, 'epoch': 7.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 120/150 [00:53<00:07,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0111, 'grad_norm': 0.093358613550663, 'learning_rate': 1e-05, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 131/150 [00:59<00:04,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0073, 'grad_norm': 0.3179018795490265, 'learning_rate': 6.666666666666667e-06, 'epoch': 8.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 141/150 [01:04<00:03,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0108, 'grad_norm': 0.7370986342430115, 'learning_rate': 3.3333333333333333e-06, 'epoch': 9.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [01:06<00:00,  4.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.004, 'grad_norm': 0.26489928364753723, 'learning_rate': 0.0, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [01:13<00:00,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 73.2607, 'train_samples_per_second': 8.19, 'train_steps_per_second': 2.047, 'train_loss': 0.7237942044933637, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=150, training_loss=0.7237942044933637, metrics={'train_runtime': 73.2607, 'train_samples_per_second': 8.19, 'train_steps_per_second': 2.047, 'total_flos': 102713602867200.0, 'train_loss': 0.7237942044933637, 'epoch': 10.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 5. 訓練設定\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"./sql_model\",\n",
    "    per_device_train_batch_size=4,\n",
    "    num_train_epochs=10,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./sql_model\\\\tokenizer_config.json',\n",
       " './sql_model\\\\special_tokens_map.json',\n",
       " './sql_model\\\\spiece.model',\n",
       " './sql_model\\\\added_tokens.json')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 6. 儲存 fine-tuned 模型\n",
    "model.save_pretrained(\"./sql_model\")\n",
    "tokenizer.save_pretrained(\"./sql_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 7. 使用模型進行推論\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"./sql_model\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./sql_model\", use_fast=False)\n",
    "\n",
    "def generate_sql(question: str):\n",
    "    schema_text = \" | \".join(\n",
    "        f\"{t}({', '.join(info['columns'])})\" for t, info in schemas.items()\n",
    "    )\n",
    "    input_text = f\"將下列中文問題轉成 SQL：{question} [SEP] 資料表結構：{schema_text}\"\n",
    "    encoding = tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=128)\n",
    "    outputs = model.generate(**encoding, max_length=128)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     q = input(\"請輸入中文問題：\")\n",
    "#     sql = generate_sql(q)\n",
    "#     print(\"→\", sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 誰住台北\n",
      "SQL: SELECT * FROM customers WHERE city = '台北';\n",
      "\n",
      "【查詢結果】\n",
      "   id name city\n",
      "0   1   小明   台北\n",
      "1   3   大雄   台北\n",
      "2  12   建志   台北\n",
      "3  27   宜庭   台北\n",
      "4  38   怡萱   台北\n"
     ]
    }
   ],
   "source": [
    "# 輸入中文問題\n",
    "q = input(\"請輸入中文問題：\")\n",
    "sql = generate_sql(q)\n",
    "print(\"Input:\", q)\n",
    "print(\"SQL:\", sql)\n",
    "\n",
    "# 建立DB連線\n",
    "conn = sqlite3.connect(\"sample_nl2sql.db\")\n",
    "\n",
    "# 執行 AI 產生的 SQL 查詢\n",
    "df = pd.read_sql_query(sql, conn)\n",
    "conn.close()\n",
    "\n",
    "print(\"\\n【查詢結果】\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python38_cuda_conda",
   "language": "python",
   "name": "python38_cuda_conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
