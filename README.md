# MengziSQL-Demo

This project demonstrates how to train a T5 model to translate Chinese natural language questions into SQL queries.

---

## ä¸­æ–‡ç‰ˆ

### ğŸš€ åŠŸèƒ½

*   ä½¿ç”¨ HuggingFace Transformers å¾®èª¿ `Langboat/mengzi-t5-base` æ¨¡å‹ã€‚
*   å°‡ä¸­æ–‡è‡ªç„¶èªè¨€å•é¡Œè½‰æ›ç‚º SQL æŸ¥è©¢ã€‚
*   åœ¨ SQLite è³‡æ–™åº«ä¸ŠåŸ·è¡Œç”Ÿæˆçš„ SQL ä¸¦ä»¥è¡¨æ ¼å½¢å¼é¡¯ç¤ºçµæœã€‚

### ğŸ“‹ ç’°å¢ƒéœ€æ±‚

*   Python 3.8+
*   `transformers`
*   `sentencepiece`
*   `datasets`
*   `accelerate`
*   `pandas`
*   `sqlite3`

### ğŸ› ï¸ æ“ä½œæ­¥é©Ÿ

#### 1. å®‰è£å¥—ä»¶

é¦–å…ˆï¼Œå®‰è£æ‰€æœ‰å¿…è¦çš„ Python å¥—ä»¶ï¼š

```bash
pip install transformers sentencepiece datasets accelerate pandas
```

#### 2. æº–å‚™è³‡æ–™åº«èˆ‡è¨“ç·´è³‡æ–™

åŸ·è¡Œ `NL2SQL.ipynb` çš„å‰å¹¾å€‹å„²å­˜æ ¼ä¾†ï¼š

*   å»ºç«‹ä¸€å€‹åç‚º `sample_nl2sql.db` çš„ SQLite è³‡æ–™åº«ã€‚
*   åœ¨è³‡æ–™åº«ä¸­å»ºç«‹ä¸€å€‹ `customers` è¡¨æ ¼ï¼Œä¸¦å¡«å…¥ç¯„ä¾‹è³‡æ–™ã€‚
*   æ ¹æ“šæ‚¨çš„è³‡æ–™åº«çµæ§‹å’Œå•é¡Œï¼Œç”Ÿæˆä¸€å€‹ `train.json` æª”æ¡ˆã€‚

#### 3. è¨“ç·´æ¨¡å‹

*   ç¹¼çºŒåŸ·è¡Œ `NL2SQL.ipynb` ä¸­çš„å„²å­˜æ ¼ä¾†è¼‰å…¥ `Langboat/mengzi-t5-base` æ¨¡å‹å’Œ tokenizerã€‚
*   è…³æœ¬æœƒé è™•ç† `train.json` ä¸­çš„è³‡æ–™ï¼Œå°‡å•é¡Œå’Œè³‡æ–™åº«çµæ§‹çµåˆèµ·ä¾†ä½œç‚ºæ¨¡å‹è¼¸å…¥ã€‚
*   ä½¿ç”¨ `Trainer` API ä¾†å¾®èª¿æ¨¡å‹ã€‚
*   è¨“ç·´å®Œæˆå¾Œï¼Œæ¨¡å‹å°‡è¢«å„²å­˜åˆ° `./sql_model` ç›®éŒ„ä¸‹ã€‚

#### 4. é€²è¡Œæ¨è«– (NL2SQL)

*   è¼‰å…¥æ‚¨å‰›å‰›åœ¨ `./sql_model` ä¸­å„²å­˜çš„å¾®èª¿æ¨¡å‹ã€‚
*   æä¾›ä¸€å€‹ä¸­æ–‡å•é¡Œ (ä¾‹å¦‚ï¼Œã€Œèª°ä½å°åŒ—ã€)ã€‚
*   æ¨¡å‹å°‡ç”Ÿæˆå°æ‡‰çš„ SQL æŸ¥è©¢ã€‚
*   è…³æœ¬æœƒåŸ·è¡Œæ­¤ SQL æŸ¥è©¢ä¸¦é¡¯ç¤ºçµæœã€‚
*   <img width="486" height="250" alt="image" src="https://github.com/user-attachments/assets/3e1f0e99-581a-40eb-9595-cd71cdb29df1" />

### ğŸ“‚ æª”æ¡ˆçµæ§‹

*   `.gitignore`: Git å¿½ç•¥æª”æ¡ˆåˆ—è¡¨ã€‚
*   `NL2SQL.ipynb`: åŒ…å«æ‰€æœ‰æ­¥é©Ÿçš„ Jupyter Notebookï¼Œå¾è³‡æ–™æº–å‚™åˆ°æ¨¡å‹è¨“ç·´å’Œæ¨è«–ã€‚
*   `sample_nl2sql.db`: (åŸ·è¡Œ Notebook å¾Œç”Ÿæˆ) ç¯„ä¾‹ SQLite è³‡æ–™åº«ã€‚
*   `train.json`: (åŸ·è¡Œ Notebook å¾Œç”Ÿæˆ) ç”¨æ–¼æ¨¡å‹å¾®èª¿çš„è¨“ç·´è³‡æ–™ã€‚
*   `sql_model/`: (åŸ·è¡Œ Notebook å¾Œç”Ÿæˆ) å„²å­˜å¾®èª¿å¾Œçš„æ¨¡å‹å’Œ tokenizerã€‚

### ğŸ™ è‡´è¬

æœ¬å°ˆæ¡ˆä½¿ç”¨äº†ç”± Langboat åœ˜éšŠé–‹ç™¼çš„ [mengzi-t5-base](https://huggingface.co/Langboat/mengzi-t5-base) æ¨¡å‹ã€‚

---

## English Version

### ğŸš€ Features

*   Fine-tune the `Langboat/mengzi-t5-base` model using HuggingFace Transformers.
*   Translate Chinese natural language questions into SQL queries.
*   Execute the generated SQL on a SQLite database and display the results in a table.

### ğŸ“‹ Requirements

*   Python 3.8+
*   `transformers`
*   `sentencepiece`
*   `datasets`
*   `accelerate`
*   `pandas`
*   `sqlite3`

### ğŸ› ï¸ Step-by-Step Guide

#### 1. Install Dependencies

First, install all the required Python packages:

```bash
pip install transformers sentencepiece datasets accelerate pandas
```

#### 2. Prepare Database and Training Data

Run the initial cells in `NL2SQL.ipynb` to:

*   Create a SQLite database named `sample_nl2sql.db`.
*   Create a `customers` table within the database and populate it with sample data.
*   Generate a `train.json` file based on your database schema and questions.

#### 3. Train the Model

*   Continue running the cells in `NL2SQL.ipynb` to load the `Langboat/mengzi-t5-base` model and tokenizer.
*   The script will preprocess the data from `train.json`, combining the questions and database schema as input for the model.
*   Fine-tune the model using the `Trainer` API.
*   Once training is complete, the model will be saved to the `./sql_model` directory.

#### 4. Perform Inference (NL2SQL)

*   Load the fine-tuned model you just saved from `./sql_model`.
*   Provide a Chinese question (e.g., "èª°ä½å°åŒ—" ).
*   The model will generate the corresponding SQL query.
*   The script will execute this SQL query and display the results.
*   <img width="486" height="250" alt="image" src="https://github.com/user-attachments/assets/9a5eb9eb-d14d-4712-b6ae-ea08f0472924" />

### ğŸ“‚ File Structure

*   `.gitignore`: A list of files for Git to ignore.
*   `NL2SQL.ipynb`: The Jupyter Notebook containing all steps, from data preparation to model training and inference.
*   `sample_nl2sql.db`: (Generated after running the notebook) The sample SQLite database.
*   `train.json`: (Generated after running the notebook) The training data for fine-tuning the model.
*   `sql_model/`: (Generated after running the notebook) Contains the fine-tuned model and tokenizer.

### ğŸ™ Acknowledgements

This project utilizes the [mengzi-t5-base](https://huggingface.co/Langboat/mengzi-t5-base) model developed by the Langboat team.
